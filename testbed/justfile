set dotenv-load := true

RUN := env_var_or_default("RUN", "python")
DOCKER := env_var_or_default("DOCKER", "podman")
export SSHPASS := "giraff"
export MANAGER_PATH := "../manager"
export IOT_EMULATION_PATH := "../iot_emulation"
export FUNCTIONS_PATH := "../openfaas-functions"

# Entrypoint, run deploy and then tunnels
_default:
    @just --list

init user *FLAGS:
    #!/usr/bin/env bash
    cat <<EOF > ~/.ssh/config
    Host !access.grid5000.fr *.grid5000.fr
    User {{ user }}
    ProxyJump {{ user }}@access.grid5000.fr
    StrictHostKeyChecking no
    UserKnownHostsFile /dev/null
    ForwardAgent yes
    EOF

    {{ RUN }} integration.py init --g5k_user={{ user }} {{ FLAGS }}

# Open SSH tunnels
[private]
tunnels +FLAGS='':
    {{ RUN }} integration.py tunnels {{ FLAGS }}

# List end nodes of the Fog network
[private]
endpoints:
    {{ RUN }} integration.py endpoints

_is_connected city_name_node_target $market_ip market_port $tmpfile:
    #!/usr/bin/env bash
    set -e
    curl -m 30 -s "$market_ip:{{ market_port }}/api/fog" -o $tmpfile
    jq -r '.[] | select(.tags[] == "{{ city_name_node_target }}") | .id' $tmpfile | sponge $tmpfile
    output=$(cat $tmpfile)
    if [ "$output" == "" ]; then
      echo "didn't find the tags"
      exit 1
    fi

_until_is_connected city_name_node_target market_ip market_port:
    #!/usr/bin/env bash
    status=1
    while [ $status -ne 0 ]; do
      tmpfile=$(mktemp)
      just _is_connected {{ city_name_node_target }} {{ market_ip }} {{ market_port }} $tmpfile
      status=$?
      rm $tmpfile
      if [ $status -ne 0 ]; then
        sleep 3
      fi
    done

[private]
deploy fog_node_image market_image $DEPLOYMENT_NAME:
    #!/usr/bin/env bash
    set -e
    echo "REFRESH?: $REFRESH"
    if [ "$REFRESH" = "true" ] ; then
      just refresh {{ fog_node_image }} {{ market_image }} $DEPLOYMENT_NAME
    else
      just fresh {{ fog_node_image }} {{ market_image }} $DEPLOYMENT_NAME
    fi
    {{ RUN }} integration.py market-ip

[private]
fresh fog_node_image market_image $DEPLOYMENT_NAME:
    {{ RUN }} integration.py up --name="$DEPLOYMENT_NAME" --walltime "$DEPLOYMENT_WALLTIME" --force
    cp -Lr current current.bak
    just _deploy {{ fog_node_image }} {{ market_image }}
    # Deploy the images on the registry, but only once since it is cached in the vm between reboots
    {{ RUN }} integration.py setup-registry

refresh_registry env_variation=".env.dev":
    #!/usr/bin/env bash
    source {{ justfile_directory() }}/env_checkpoint{{ env_variation }}.sh
    {{ RUN }} integration.py setup-registry

[private]
refresh fog_node_image market_image $DEPLOYMENT_NAME:
    #!/usr/bin/env bash
    source utils.sh
    set -e
    # reboot and wait for reasonable time if we can detect the machines did reboot
    {{ RUN }} integration.py restart
    sleep 10
    ackreboot(){
      set -e
      timeout 500 {{ RUN }} integration.py ack-reboot
    }
    log "ACK reboot" false ackreboot

    # verify the machines did in fact reboot
    check_reboot(){
    timeout 500 sh <<EOT
      set -e
      check_restart() {
        set -e
        cp -fr current.bak current.new
        ln -sfn current.new current
        rm ~/.ssh/known_hosts || true
        {{ RUN }} integration.py check-rebooted
      }
      until check_restart; do
        sleep 30
      done
    EOT
    }
    log "wait and check the system is responsive and rebooted" false check_reboot

    # pursue installation process for experiments
    just _deploy {{ fog_node_image }} {{ market_image }}

# Delete the Job on grid'5000 and local EnosLib files
[private]
clean:
    {{ RUN }} integration.py clean || true
    rm -rf enos_* current cachedir __enos*

# Refresh the container images hosted by k3s on all deployed nodes
_deploy fog_node_image market_image:
    #!/usr/bin/env bash
    set -e
    if [ "$DEV" = "true" ]; then
      export RUST_LOG="warn,fog_node=trace,openfaas=trace,market=trace"
    fi
    {{ RUN }} integration.py network
    {{ RUN }} integration.py iot-emulation
    timeout 10m {{ RUN }} integration.py k3s-setup
    {{ RUN }} integration.py k3s-deploy --fog_node_image={{ fog_node_image }} --market_image={{ market_image }}

[private]
expe env_variation IOT_IP MARKET_IP TARGET_NODES:
    #!/usr/bin/env bash
    set -e
    set -a
    source "{{ justfile_directory() }}/{{ env_variation }}"
    source "{{ justfile_directory() }}/.env"
    set +a
    export IOT_IP={{ IOT_IP }}
    export MARKET_IP={{ MARKET_IP }}
    export TARGET_NODES="{{ TARGET_NODES }}"
    export EXPE_LOAD_FILE="{{ justfile_directory() }}/requests{{ env_variation }}"
    export -p | sed 's/declare -x /export /' > env_checkpoint{{ env_variation }}.sh
    export COLLECTOR_URL="$IOT_IP:4317"
    expe

# Runs a command (default to expe) from the checkpoint saved with all the environment variables set for the current container the command will run in
from_checkpoint env_variation=".env.dev" *command="expe":
    #!/usr/bin/env bash
    source {{ justfile_directory() }}/env_checkpoint{{ env_variation }}.sh
    {{ command }}

[private]
scenario archive_name env_variation +city_name_node_targets:
    #!/usr/bin/env bash
    just _scenario "{{ archive_name }}" "{{ env_variation }}" {{ city_name_node_targets }}

    if [ "$DEV" = "true" ]; then
        printf "DEV activated ; waiting indefinitely\n"
        sleep 9999999999;
    fi

_scenario archive_name env_variation +city_name_node_targets:
    #!/usr/bin/env bash
    set -e
    source utils.sh

    MARKET_IP=$({{ RUN }} integration.py market-ip | grep address | sed 's/address: //')

    function verify_connections {
      set -e
      parallel --will-cite \
            -j5 \
            --timeout 500 \
            --halt soon,fail=1 \
            just _until_is_connected {1} $MARKET_IP $MARKET_LOCAL_PORT \
            ::: {{ city_name_node_targets }}
    }
    log "verify fog interconnections" false verify_connections

    NODE_TARGETS=()
    tmpfile=$(mktemp)

    for city in {{ city_name_node_targets }}; do
        echo "Getting connection to $city"
        curl -s  "$MARKET_IP:$MARKET_LOCAL_PORT/api/fog" -o $tmpfile
        jq -r ".[] | select(any(.tags[]; . == \"$city\")) | .id" $tmpfile | sponge $tmpfile
        TARGET="$(cat $tmpfile)"
        if [ "$TARGET" = "" ]; then
          echo "Could not find city to extract its id and use it as a target for the experiment"
          exit 1
        fi
        NODE_TARGETS+=("$(cat $tmpfile)")
    done

    rm $tmpfile
    echo "got ${#NODE_TARGETS[@]} ips"

    IOT_IP=$(just endpoints | sed -nE 's/Iot emulation IP -> (.*)/\1/p')

    printf -v joined '%s\t' "${NODE_TARGETS[@]}"
    export TARGET_NODE_NAMES="{{ city_name_node_targets }}"
    log "sleeping 60 secs" false sleep 60

    do_expe(){
        set -e
        export DOCKER_REGISTRY="$MARKET_IP:5555"
        # Use local registry as cold start is not important yet
        export DOCKER_REGISTRY="127.0.0.1:5555"
        just expe "{{ env_variation }}" $IOT_IP $MARKET_IP "$joined"
    }
    echo "experiment ({{ env_variation }} for $EXPERIMENT_DURATION secs)"
    do_expe

    log "sleeping $WAIT_TIME secs" false sleep $WAIT_TIME

    export COLLECT_ARCHIVE_NAME="{{ archive_name }}"
    {{ RUN }} integration.py collect

    log "sleeping 60 secs" false sleep 60

[private]
scenarii +city_name_node_targets:
    #!/usr/bin/env bash
    set -e

    function run_scenario() {
        echo "Using image $IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$2 and $IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$3 (exec #$1; env $4)"
        set -e
        if [ $1 -eq 1 ]; then
            just deploy "$IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$2" "$IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$3" $DEPLOYMENT_NAME
        else
            just refresh "$IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$2" "$IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$3" $DEPLOYMENT_NAME
        fi
        just scenario "$DEPLOYMENT_NAME-$2-$3-$4" "$4" {{ city_name_node_targets }}
    }

    echo "Deploying..."

    export -f run_scenario
    if [ $DEV == "true" ]; then
      ENV_VARIATIONS=".env.dev"
    fi
    parallel --tty -j1 --shuf --will-cite \
        --joblog ./joblog \
        --retries 3 \
        run_scenario {#} {1} {2} {3}\
        ::: $(echo ${FOG_NODE_IMAGE_TAGS[@]}) \
        :::+ $(echo ${MARKET_IMAGE_TAGS[@]}) \
        ::: $(echo ${ENV_VARIATIONS[@]})

    #for INDEX in $(seq 1 3); do
    #    parallel --will-cite --tty --joblog ./joblog --retry-failed
    #done

collect:
    #!/usr/bin/env bash
    mkdir -p metrics
    export COLLECT_ARCHIVE_NAME="local.env_LOCAL-fog_node_local-market_local"
    {{ RUN }} integration.py collect --address $INFLUX_ADDRESS

_collect:
    mkdir -p metrics
    {{ RUN }} integration.py collect

logs *FLAGS:
    {{ RUN }} integration.py logs {{ FLAGS }}

[private]
docker_enos name expe_dir cmd="bash":
    #!/usr/bin/env bash
    set -e
    source utils.sh
    eval $(ssh-agent -s)

    function sync_files {
      rsync -rL {{ justfile_directory() }}/ {{ expe_dir }}
    }
    log "sync files with experiment container" false sync_files

    echo "LOAD_NET: $LOAD_NETWORK_FILE"

    export REFRESH="false"
    if {{ DOCKER }} ps -a --format '{{{{.Names}}}}' | grep -wq "{{ name }}"; then
        export REFRESH="true"
        {{ DOCKER }} exec "{{ name }}" bash -c -E "export REFRESH=$REFRESH; {{ cmd }}"
    else
        {{ DOCKER }} run -it --rm \
            --privileged \
            --cap-add=ALL \
            --pids-limit -1 \
            --workdir /home/enos \
            -v /lib/modules:/lib/modules \
            -v {{ expe_dir }}:/home/enos \
            -v {{ justfile_directory() }}/metrics-arks:/home/enos/metrics-arks \
            -v {{ justfile_directory() }}/logs:/home/enos/logs \
            -v {{ justfile_directory() }}/enosvm:/home/enos/enosvm \
            -v $LOAD_NETWORK_FILE:/home/enos/net:ro \
            -v ~/.python-grid5000.yaml:/root/.python-grid5000.yaml:ro \
            -v ~/.ssh/id_rsa:/root/.ssh/id_rsa:ro \
            -v ~/.ssh/id_rsa.pub:/root/.ssh/id_rsa.pub:ro \
            -v $(readlink -f $SSH_AUTH_SOCK):/ssh-agent \
            -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt:ro \
            -e SSH_AUTH_SOCK=/ssh-agent \
            -e DEPLOYMENT_NAME="{{ name }}" \
            -e LOAD_NETWORK_FILE=/home/enos/net \
            -e REFRESH="false" \
            --name "{{ name }}" \
            --cgroup-manager=cgroupfs \
            enos_deployment:latest bash -c -E "{{ cmd }}"
        fi


ssh_into_expe city master_node_ip:
    ssh -tt {{city}}.grid5000.fr 'exec ssh -tt root@{{ master_node_ip }} '\''cd /home/enos && source env.source && exec {{ DOCKER }} exec -it $({{ DOCKER }} ps -q | head -n1) bash --init-file "<(echo \"source env.source ; exec bash -i\")" '\'''


[private]
_inside_docker_scenearii +city_name_node_targets:
    #!/usr/bin/env bash
    echo "Generating requests for all subsequent experiments..."
    just scenarii {{ city_name_node_targets }}
    res=$?
    if [ $DEV_SLEEP_AFTER_CRASH = "true" ]; then
      if [ $res -ne 0 ]; then
        echo "DEV_SLEEP_AFTER_CRASH enabled, sleeping until infinity"
        sleep 9999999999
      fi
    fi
    just clean

# Investigate that
[private]
docker_scenarii name expe_dir +city_name_node_targets:
    #!/usr/bin/env bash
    set -e
    if [ $DEV == "true" ]; then
      ENV_VARIATIONS=".env.dev"
    fi
    for variation in ${ENV_VARIATIONS[@]}; do
    (
      set -o allexport
      source "{{ justfile_directory() }}/.env"
      source "{{ justfile_directory() }}/$variation"
      set +o allexport
      EXPE_SAVE_FILE="{{ expe_dir }}/requests$variation" TARGET_NODE_NAMES="{{ city_name_node_targets }}" expe
    )
    done
    just docker_enos {{ name }} {{ expe_dir }} "just _inside_docker_scenearii {{ city_name_node_targets }}"

_docker_campaign name expe_dir:
    #!/usr/bin/env bash
    set -e
    cities=()
    for input in $({{ RUN }} integration.py iot-connections); do cities[${#cities[@]}]="'$input'"; done
    just docker_scenarii {{ name }} {{ expe_dir }} ${cities[@]}

single_campaign name dotenvfile_default:
    #!/usr/bin/env bash
    set -e
    expe_dir="/dev/shm/{{ name }}"
    mkdir -p $expe_dir

    cp {{ dotenvfile_default }} $expe_dir/.env
    cp .env* "$expe_dir/"

    cp definitions.py $expe_dir/definitions.py
    mkdir -p metrics-arks logs logs_campaign

    today=$( date +%Y%m%d )
    number=0
    fname={{ name }}-$today.log
    while [ -e "$fname" ]; do
        printf -v fname '%s-%02d.log' "{{ name }}-$today" "$(( ++number ))"
    done

    just _docker_campaign {{ name }} $expe_dir |& tee -a logs_campaign/$fname

# Builds and upload container images
build_required_images user skip_rebuild:
    #!/usr/bin/env bash
    set -e
    source utils.sh
    do_images(){
      set -xe
      read -ra tags <<<"$FOG_NODE_IMAGE_TAGS"
      read -ra market_tags <<<"$MARKET_IMAGE_TAGS"

      commands=(
          "cd $MANAGER_PATH && nix develop .#manager -c just ghcr {{ user }} $(echo ${tags[@]}) $(echo ${market_tags[@]})"
          "cd $IOT_EMULATION_PATH && nix develop .#iot_emulation -c just ghcr {{ user }}"
          "cd $FUNCTIONS_PATH && nix develop .#openfaas-functions -c just ghcr_all {{ user }}"
      )

      parallel --will-cite --halt-on-error 2 {1} 2> /dev/null ::: "${commands[@]}"
    }

    log "container images" {{ skip_rebuild }} do_images

_docker_campaign_in_env variation experiments_dotfile single_experiment_dotenvfile:
    #!/usr/bin/env bash
    set -e
    source utils.sh

    function expe_command() {
        set -e
        export ii=$1

        sleep 1

        # Calculate current time in seconds
        current_time=$( date +%s )

        # Convert job duration to seconds
        IFS=":" read hours minutes seconds <<< "${DEPLOYMENT_WALLTIME}"
        job_duration_seconds=$(bc <<< "${hours}*3600 + ${minutes}*60 + ${seconds}")

        # Calculate threshold in seconds
        next_day=$(date -d ${DO_NOT_EXECUTE_IF_ENDING_AFTER} +"%Y%m%d")
        threshold_time=$(date -d "${next_day} ${DO_NOT_EXECUTE_IF_ENDING_AFTER_HOUR}" +%s)

        # Compare times and decide whether to execute the command
        if (( current_time + job_duration_seconds > threshold_time )); then
            >&2 echo "Job will finish after $DO_NOT_EXECUTE_IF_ENDING_AFTER_HOUR the '$DO_NOT_EXECUTE_IF_ENDING_AFTER' day. Command will not be executed."
            exit 127
        fi

        suffix=`echo "$ii"_"$current_time"`
        timeout --foreground ${job_duration_seconds} just single_campaign "{{ variation }}{{ single_experiment_dotenvfile }}_$suffix" "{{ single_experiment_dotenvfile }}"
    }

    # Import all the settings for multiple experiments and load the var as env vars
    set -o allexport
    source {{ experiments_dotfile }}
    set +o allexport

    if [ "$DEV" = "true" ]; then
        export NETWORK_FILE=$(mktemp)
        gen_network() {
          set -e
          if [ "$DEV_NETWORK" = "true" ]; then
              export LOAD_NETWORK_FILE=$NETWORK_FILE
          else
              export SAVE_NETWORK_FILE=$NETWORK_FILE
              set -- $SIZE_MULTIPLIERS
              export SIZE_MULTIPLIER=$1
              set -- $MIN_NUMBER_VMS
              export MIN_NB_VMS=$1
              set -- $MAX_NUMBER_VMS
              export MAX_NB_VMS=$1

              {{ RUN }} definitions.py
              export LOAD_NETWORK_FILE=$SAVE_NETWORK_FILE

              unset SAVE_NETWORK_FILE
          fi
        }
        log "generate fog network parameters" false gen_network
        export LOAD_NETWORK_FILE=$NETWORK_FILE
        just single_campaign "{{ variation }}{{ single_experiment_dotenvfile }}_DEV" {{ single_experiment_dotenvfile }}
        exit 0
    fi

    mkdir -p $JOB_DIR
    if [ $TYPE == "first_run" ]; then
        rm -rf $JOB_DIR/*
        parallel --will-cite \
            --retries 5 \
            SAVE_NETWORK_FILE=$JOB_DIR/{1}-{4}.net \
            SIZE_MULTIPLIER={1} \
            MIN_NB_VMS={2} \
            MAX_NB_VMS={3} \
            {{ RUN }} definitions.py \
            ::: $SIZE_MULTIPLIERS \
            :::+ $MIN_NUMBER_VMS \
            :::+ $MAX_NUMBER_VMS \
            ::: $(seq 1 $NB_REPETITIONS)
    fi

    for i in $(seq 1 $NB_REPETITIONS); do
        args+=("")
    done

    export free_port=$(comm -23 <(seq 49152 65535 | sort) <(ss -Htan | awk '{print $4}' | cut -d':' -f2 | sort -u) | shuf | head -n 1)

    function encapsulated_expe_command() {
        set -e
        export LOAD_NETWORK_FILE=$2
        echo "Running the expe command with LOAD_NETWORK_FILE=$LOAD_NETWORK_FILE"
        expe_command $1
    }

    # Enable job control
    function run_experiments {
      set -m
      export -f expe_command
      export -f encapsulated_expe_command

      set +e
      if [ ! -f $JOB_LOG ] && [ "$TYPE" != "first_run" ]; then
          >&2 echo "the action is TYPE=$TYPE; cannot run without JOB_LOG=$JOB_LOG existing"
          exit 1
      fi
      if [ $TYPE == "retry" ]; then
          (parallel --will-cite --retry-failed --joblog $JOB_LOG)
      else
          cmd=$(cat <<EOF
          --joblog $JOB_LOG \
          -j $NB_IN_PARALLEL \
          encapsulated_expe_command {#} '$JOB_DIR/'{1}-{2}.net \
          ::: $SIZE_MULTIPLIERS \
          ::: $(seq 1 $NB_REPETITIONS)
    EOF
    )
          if [ $TYPE == "resume" ]; then
              parallel --will-cite --shuf --resume $cmd
          else
              rm $JOB_LOG || true
              parallel --will-cite --shuf $cmd
          fi
      fi
    }
    run_experiments
    #log "run the experiments" false run_experiments

    echo "Here is the JOB_LOG:"
    cat $JOB_LOG

dry-experiment $CLUSTER SIZE_MULTIPLIERS:
    #!/usr/bin/env bash
    parallel --will-cite -k \
        export SIZE_MULTIPLIER={1} FILE='$(mktemp)' \
        ";" SAVE_NETWORK_FILE='$FILE' {{ RUN }} definitions.py \
        "&&" LOAD_NETWORK_FILE='$FILE' {{ RUN }} integration.py up --dry-run \
        ";" rm '$FILE' \
        ::: {{ SIZE_MULTIPLIERS }}

city experiments_dotfile=".experiments.env":
    #!/usr/bin/env bash
    set -o allexport
    source {{ experiments_dotfile }}
    {{ RUN }} master.py get-city

# Uploads the necessary files for the experiments to the specified node in .env and <experiments_dotfile>. Uploading and building VMs can be skipped using <skip_vm>
upload experiments_dotfile=".experiments.env" skip_vms="false":
    #!/usr/bin/env bash
    set -e
    set -o allexport
    source {{ experiments_dotfile }}
    source utils.sh
    city=$({{ RUN }} master.py get-city)

    push_master_vm(){
      set -e
      rm -f ./sda.raw || true
      script_vm=$(nix build --extra-experimental-features nix-command --extra-experimental-features flakes .#nixosConfigurations.enosvm.config.system.build.diskoImagesScript --print-out-paths --no-link --quiet)
      $script_vm --build-memory 4096
      vm_path_raw=./sda.raw
      vm_path=./sda.qcow2
      nix develop .#enosvm -c qemu-img convert -c -f raw -O qcow2 $vm_path_raw $vm_path
      rsync -cazpq --inplace --stats --perms --chmod=u+rwx,g+rwx,o+rwx $vm_path $city.grid5000.fr:~/nixos.env.qcow2
    }

    push_vms(){
      set -e
      cd iso
      nix develop .#iso -c just upload $city
    }

    push_files(){
      set -e
      rsync -cazpq --inplace --stats --chmod=u+rwx,g+rwx,o+rwx emul *.py utils.sh .env* {{ experiments_dotfile }} justfile pipelines $city.grid5000.fr:~/enosvm/
    }

    rm_distant_known_hosts (){
      set -e
      ssh $city.grid5000.fr rm .ssh/known_hosts
    }

    make_enosvm_dir(){
      set -e
      ssh $city.grid5000.fr mkdir -p enosvm
      ssh $city.grid5000.fr [ -e enosvm ] "&&" rm -rf enosvm
    }

    log "make and cleaning enosvm dir" false make_enosvm_dir
    #log "remove g5k ssh known_hosts" false rm_distant_known_hosts
    log "config files" false push_files
    log "master vm" {{ skip_vms }} push_master_vm
    log "fog node vms" {{ skip_vms }} push_vms
    echo -e "all files rsynced \033[1;32mOK\033[0m"

master_exec user experiments_dotfile=".experiments.env" skip_vms="false" skip_rebuild="false":
    #!/usr/bin/env bash
    set -e
    set -o allexport
    source {{ experiments_dotfile }}
    set +o allexport
    source utils.sh

    city=$({{ RUN }} master.py get-city)
    username=$({{ RUN }} master.py get-username)

    function set_nfs {
        echo "nfs:/export/home/$username" | tee iso/config/g5k.nfs.txt
    }
    function set_ntp {
        echo "ntp.$city.grid5000.fr" | tee iso/config/ntp-servers.txt
    }
    log "use $username's NFS volume" false set_nfs
    log "use $city's NTP clock for VMs" false set_ntp

    parallel --will-cite ::: \
      'just upload {{ experiments_dotfile }} {{ skip_vms }}' \
      'just build_required_images {{ user }} {{ skip_rebuild }}'

    NAME=`git rev-parse --abbrev-ref HEAD`

    {{ RUN }} master.py up --name $NAME --walltime $MASTER_WALLTIME --force
    {{ RUN }} master.py run-command

master_refresh user experiments_dotfile=".experiments.env" skip_rebuild="false":
    #!/usr/bin/env bash
    set -e
    set -o allexport
    source {{ experiments_dotfile }}
    set +o allexport

    parallel --will-cite ::: \
      'just upload {{ experiments_dotfile }} true' \
      'just build_required_images {{ user }} {{ skip_rebuild }}'
    {{ RUN }} master.py run-command-refresh

master_docker_campaign variation="valuation_rates" experiments_dotfile=".experiments.env" single_experiment_dotenvfile=".env":
    just _docker_campaign_in_env {{ variation }} {{ experiments_dotfile }} {{ single_experiment_dotenvfile }}

master_run:
    nix develop .#enosvm -c just _master_run

_master_run:
    #!/usr/bin/env bash
    set -e
    rm -f ./sda.raw || true
    script_vm=$(nix build --extra-experimental-features nix-command --extra-experimental-features flakes .#nixosConfigurations.enosvm.config.system.build.diskoImagesScript --print-out-paths --no-link --quiet)
    $script_vm --build-memory 4096
    vm_path_raw=./sda.raw
    vm_path=./sda.qcow2
    qemu-img convert -f raw -O qcow2 $vm_path_raw $vm_path

    temp=nixos.qcow2
    cp $vm_path $temp
    chmod u+rwx $temp

    qemu-kvm \
        -cpu max \
        -name nixos \
        -m 4096 \
        -smp 4 \
        -drive cache=writeback,file="$temp",id=drive1,if=none,index=1,werror=report -device virtio-blk-pci,drive=drive1 \
        -net nic,netdev=giraff.master_vm,model=virtio -netdev user,id=giraff.master_vm,hostfwd=tcp::2222-:22 \
        -enable-kvm \
        -nographic&

    wait

master_ssh_in:
    nix develop .#enosvm -c sshpass -e ssh -t -oUserKnownHostsFile=/dev/null -oStrictHostKeyChecking=no root@127.0.0.1 -p 2222

get_metrics_back grep="" folder="metrics-arks" experiments_dotfile=".experiments.env":
    #!/usr/bin/env bash
    set -o allexport
    source {{ experiments_dotfile }}
    set +o allexport
    city=$({{ RUN }} master.py get-city)
    echo $city
    mkdir -p metrics-arks
    output1=$(ls ./metrics-arks | grep {{ grep }})
    ssh $city.grid5000.fr ls {{ folder }} | grep {{ grep }} | parallel --will-cite -j5 rsync -cazpq $city.grid5000.fr:~/{{ folder }}/{} ./metrics-arks/{}
    output2=$(ls ./metrics-arks | grep {{ grep }})
    diff_output=$(diff <(echo "$output1") <(echo "$output2"))
    echo -e "$diff_output"

[private]
test_expe experiments_dotfile=".experiments.env":
    #!/usr/bin/env bash
    set -o allexport
    source {{ experiments_dotfile }}
    set +o allexport
    export TARGET_NODE_NAMES=toto
    export TARGET_NODES=toto
    EXPE_SAVE_FILE=toto.txt expe

[private]
test_definitions experiments_dotfile=".experiments.env":
    #!/usr/bin/env bash
    set -o allexport
    source {{ experiments_dotfile }}
    set +o allexport
    export SAVE_NETWORK_FILE=/dev/null
    python definitions.py
